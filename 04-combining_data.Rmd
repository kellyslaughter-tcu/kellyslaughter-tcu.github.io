# Combining Data {#comb}

The following data sets are now available:

* **London_Gold_AM**: Daily price of gold
* **sentiment_data_by_date**: Daily Twitter and Reddit social data 
* **TRIP_wide**: Daily Tripwire stock price from last two weeks
* **BEA_tibble_unemployment_ins**: First three months of 2020 unemployment insurance

As we combined the Twitter and Reddit data sets in \@ref(txt), we will want to combine all data sets into a single set; this is often the most convenient way to develop visualizations. We are analyzing by date, and each data set includes a date which, conveniently, is in the same format of YYYY-MM-DD. 

However, one theory might be that the social data sentiments precede changes to the gold prices. In other words, when we compare data, we want to look at Twitter as of Monday to examine the gold price on Tuesday. One convenient way to support this goal is simply to subtract one from the social media `created_at` date (a better way may be to add a new date field to all the data sets and adjust the values as wished).

We also rename the variable storing the price of gold, `USD (AM)`, as `gold_morning_price`.  

We use `inner_join` again, first combining `sentiment_data_by_date` and `London_Gold_AM` into an `all_data` data set, then through another `inner_join` combining the `all_data` with the data set `TRIP_wide`.

```{r Combine Daily Data, message = FALSE, warning = FALSE}

sentiment_data_by_date$created_at <- sentiment_data_by_date$created_at -1 # Alter date to day before as we assume social media is a leading indicator
London_Gold_AM <- London_Gold_AM %>% rename(gold_morning_price = 'USD (AM)')

all_data <- inner_join(sentiment_data_by_date, London_Gold_AM, by = c("created_at" = "Date")) # 'created_at' will be the preserved key
all_data <- inner_join(all_data, TRIP_wide, by = c("created_at" = "index"))

```

The unemployment insurance is reported on a monthly basis, so we do not have a row to row match by date. Let's assume a three-month lag between the 'macro' condition of unemployment and the daily prices and sentiment. Thus, gold prices in May are associated with unemployment insurance in February. Thus, every price row by date in May will have the same BEA value from February.

We need matching values across the data sets for successfully joining the data. To do so, we will 'extract' the month as an integer from the date fields. We will use the `str_sub` command courtesy of the `stringr`[@R-stringr] package against the BEA data (and then add three to synch February with May). 

As we are using an `inner_join`, any unmatched rows are lost. So, if we did not have any February dates in the BEA data set, we would have no data from the join. Keep that in mind as you chose your own lagging and leading relationships.

```{r Combine-Daily-and-Monthly-Data, message = FALSE, warning = FALSE}

library(stringr)
library(lubridate)

BEA_tibble_unemployment_ins <- mutate(BEA_tibble_unemployment_ins, effect_month = as.integer(str_sub(TimePeriod, 6L, 7L)) + 3L) 
# TimePeriod is not a date variable, it is a string (char). str_sub lets us extract the month
# as.integer turns the extracted month into a number. we then add three to the month to allow a match as a leading indicator
all_data <- mutate(all_data, effect_month = as.integer(month(created_at))) # Change month to integer to allow join

all_data <- inner_join(all_data, BEA_tibble_unemployment_ins, by = c("effect_month" = "effect_month")) # Adding the by is not necessary as the only common field between the two data sets is effect_date, but as data sets evolve, fields may be added that could inadvertently affect the join

# Let's take a subset of only variables we plan to use
final_data <- select(all_data, created_at, n, total_sentiment, negative_words, Paris_count, gold_morning_price, TRIP.Diff, TRIP.Volume, DataValue)

```

The final data set has one row for each word in each tweet or reddit post with the (repeated) associated gold prices and stock price changes for Tripwire as provided in Table \@ref(tab:Final-Data-Table).
```{r Final-Data-Table, echo = FALSE, results = 'asis'}

kable(head(final_data), caption = "Final Data Set")

```

