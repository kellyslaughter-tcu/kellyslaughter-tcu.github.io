<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Text Analysis | Neeley BIS Data Science Competition Summer 2020</title>
  <meta name="description" content="Data Science Competition, 2020." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Text Analysis | Neeley BIS Data Science Competition Summer 2020" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Data Science Competition, 2020." />
  <meta name="github-repo" content="kellyslaughter-tcu/BIS-Data-Science-Competition-2020" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Text Analysis | Neeley BIS Data Science Competition Summer 2020" />
  
  <meta name="twitter:description" content="Data Science Competition, 2020." />
  

<meta name="author" content="Kelly T Slaughter" />


<meta name="date" content="2020-06-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data.html"/>
<link rel="next" href="comb.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Overview</a></li>
<li class="chapter" data-level="2" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>2</b> Obtaining External Data</a><ul>
<li class="chapter" data-level="2.1" data-path="data.html"><a href="data.html#primary-functions"><i class="fa fa-check"></i><b>2.1</b> Primary Functions</a></li>
<li class="chapter" data-level="2.2" data-path="data.html"><a href="data.html#financial-data"><i class="fa fa-check"></i><b>2.2</b> Financial Data</a><ul>
<li class="chapter" data-level="2.2.1" data-path="data.html"><a href="data.html#commodity-prices"><i class="fa fa-check"></i><b>2.2.1</b> Commodity Prices</a></li>
<li class="chapter" data-level="2.2.2" data-path="data.html"><a href="data.html#stock-prices"><i class="fa fa-check"></i><b>2.2.2</b> Stock Prices</a></li>
<li class="chapter" data-level="2.2.3" data-path="data.html"><a href="data.html#twitter"><i class="fa fa-check"></i><b>2.2.3</b> Twitter</a></li>
<li class="chapter" data-level="2.2.4" data-path="data.html"><a href="data.html#reddit"><i class="fa fa-check"></i><b>2.2.4</b> Reddit</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data.html"><a href="data.html#economic-data"><i class="fa fa-check"></i><b>2.3</b> Economic Data</a><ul>
<li class="chapter" data-level="2.3.1" data-path="data.html"><a href="data.html#unemployment-insurance"><i class="fa fa-check"></i><b>2.3.1</b> Unemployment Insurance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="txt.html"><a href="txt.html"><i class="fa fa-check"></i><b>3</b> Text Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="txt.html"><a href="txt.html#primary-functions-1"><i class="fa fa-check"></i><b>3.1</b> Primary Functions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="comb.html"><a href="comb.html"><i class="fa fa-check"></i><b>4</b> Combining Data</a><ul>
<li class="chapter" data-level="4.1" data-path="comb.html"><a href="comb.html#primary-functions-2"><i class="fa fa-check"></i><b>4.1</b> Primary Functions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="viz.html"><a href="viz.html"><i class="fa fa-check"></i><b>5</b> Visualization</a><ul>
<li class="chapter" data-level="5.1" data-path="viz.html"><a href="viz.html#primary-functions-3"><i class="fa fa-check"></i><b>5.1</b> Primary Functions</a></li>
<li class="chapter" data-level="5.2" data-path="viz.html"><a href="viz.html#data-prep"><i class="fa fa-check"></i><b>5.2</b> Data Prep</a></li>
<li class="chapter" data-level="5.3" data-path="viz.html"><a href="viz.html#plots"><i class="fa fa-check"></i><b>5.3</b> Plots</a><ul>
<li class="chapter" data-level="5.3.1" data-path="viz.html"><a href="viz.html#density"><i class="fa fa-check"></i><b>5.3.1</b> Density</a></li>
<li class="chapter" data-level="5.3.2" data-path="viz.html"><a href="viz.html#line"><i class="fa fa-check"></i><b>5.3.2</b> Line</a></li>
<li class="chapter" data-level="5.3.3" data-path="viz.html"><a href="viz.html#bubbleplot"><i class="fa fa-check"></i><b>5.3.3</b> Bubbleplot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="publishing.html"><a href="publishing.html"><i class="fa fa-check"></i><b>6</b> Publishing</a><ul>
<li class="chapter" data-level="6.1" data-path="publishing.html"><a href="publishing.html#bibliography"><i class="fa fa-check"></i><b>6.1</b> Bibliography</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="short.html"><a href="short.html"><i class="fa fa-check"></i><b>7</b> Short Version</a><ul>
<li class="chapter" data-level="7.1" data-path="short.html"><a href="short.html#prep"><i class="fa fa-check"></i><b>7.1</b> Prep</a></li>
<li class="chapter" data-level="7.2" data-path="short.html"><a href="short.html#step-1---microsoft-data"><i class="fa fa-check"></i><b>7.2</b> Step 1 - Microsoft Data</a></li>
<li class="chapter" data-level="7.3" data-path="short.html"><a href="short.html#step-2---twitter-data"><i class="fa fa-check"></i><b>7.3</b> Step 2 - Twitter Data</a></li>
<li class="chapter" data-level="7.4" data-path="short.html"><a href="short.html#step-3---create-scores-for-the-twitter-data"><i class="fa fa-check"></i><b>7.4</b> Step 3 - Create Scores for the Twitter Data</a></li>
<li class="chapter" data-level="7.5" data-path="short.html"><a href="short.html#step-4---combine-the-microsoft-stock-price-data-and-twitter-data"><i class="fa fa-check"></i><b>7.5</b> Step 4 - Combine the Microsoft Stock Price Data and Twitter Data</a></li>
<li class="chapter" data-level="7.6" data-path="short.html"><a href="short.html#step-5---create-a-line-graph"><i class="fa fa-check"></i><b>7.6</b> Step 5 - Create a Line Graph</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="shortnm.html"><a href="shortnm.html"><i class="fa fa-check"></i><b>8</b> Short Version, No Social Media</a><ul>
<li class="chapter" data-level="8.1" data-path="shortnm.html"><a href="shortnm.html#prep---load-the-packages-listed-below."><i class="fa fa-check"></i><b>8.1</b> Prep - Load the packages listed below.</a></li>
<li class="chapter" data-level="8.2" data-path="shortnm.html"><a href="shortnm.html#step-1---stock-data"><i class="fa fa-check"></i><b>8.2</b> Step 1 - Stock Data</a></li>
<li class="chapter" data-level="8.3" data-path="shortnm.html"><a href="shortnm.html#step-2---energy-data"><i class="fa fa-check"></i><b>8.3</b> Step 2 - Energy data</a></li>
<li class="chapter" data-level="8.4" data-path="shortnm.html"><a href="shortnm.html#step-3---combine-the-stock-price-data-and-energy-data"><i class="fa fa-check"></i><b>8.4</b> Step 3 - Combine the Stock Price Data and energy data</a></li>
<li class="chapter" data-level="8.5" data-path="shortnm.html"><a href="shortnm.html#step-4---create-a-plot"><i class="fa fa-check"></i><b>8.5</b> Step 4 - Create a plot</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Neeley BIS Data Science Competition<br/>Summer 2020</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="txt" class="section level1">
<h1><span class="header-section-number">3</span> Text Analysis</h1>
<h5>
<a href="03-text_analysis.Rmd">rmd version of file</a>
</h5>
<p>In this chapter we will perform simple text analysis - count and sentiment by word. Detailed guidance for text mining is provided at <a href="https://www.tidytextmining.com/tidytext.html">Text Mining with R</a><span class="citation">(Xie <a href="#ref-xie2020" role="doc-biblioref">2020</a><a href="#ref-xie2020" role="doc-biblioref">a</a>)</span>. We first need to tokenize the text (i.e., break the text apart into smaller units for analysis). We will tokenize by word. Instead of tokenizing by word, you can tokenize by n-gram, e.g., pairs, triplets, etc. of words via <code>vacation_tweets_tt2 &lt;- vacation_tweets_df %&gt;% unnest_tokens(bigram, text, token = "ngrams", n = 2)</code>. We will use the command <code>unnest_tokens()</code> from the <strong>tidytext</strong><span class="citation">(Robinson and Silge <a href="#ref-R-tidytext" role="doc-biblioref">2020</a>)</span> package to do our work.</p>
<div id="primary-functions-1" class="section level2">
<h2><span class="header-section-number">3.1</span> Primary Functions</h2>
<ul>
<li><code>unnest_tokens()</code> via the <strong>tidytext</strong> package: Tokenize social media text</li>
<li><code>anti_join()</code> via the <strong>dplyr</strong> package: Remove ‘common’ words from text</li>
<li><code>inner_join()</code> via the <strong>dplyr</strong> package: Assign sentiment scores via lexicon available via the <strong>textdata</strong> package
<hr></li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="txt.html#cb19-1"></a><span class="kw">library</span>(tidytext)</span>
<span id="cb19-2"><a href="txt.html#cb19-2"></a></span>
<span id="cb19-3"><a href="txt.html#cb19-3"></a><span class="co"># Create tokens (in our case, each word becomes a distinct value)</span></span>
<span id="cb19-4"><a href="txt.html#cb19-4"></a>vacation_tweets_tt &lt;-<span class="st"> </span>vacation_tweets_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unnest_tokens</span>(word, text) <span class="co"># How do words with special characters like hashtags tokenized?</span></span>
<span id="cb19-5"><a href="txt.html#cb19-5"></a>vacation_reddit_tt &lt;-<span class="st"> </span>reddit_data[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unnest_tokens</span>(word, comment) </span></code></pre></div>
<p>Stop words are “contextless” words that provide more clutter than information and are often removed from the text before analysis. stop_words include:</p>
<ul>
<li>a</li>
<li>about</li>
<li>actually</li>
</ul>
<p>and so forth. A data set of common stop words is included in the <strong>tidytext</strong> package. Below we use the <strong>dplyr</strong> command <code>anti_join()</code> that removes all word tokens appearing in the stop_words list.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="txt.html#cb20-1"></a>vacation_tweets_tt &lt;-<span class="st"> </span>vacation_tweets_tt <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">anti_join</span>(stop_words, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;word&quot;</span> =<span class="st"> &quot;word&quot;</span>)) <span class="co"># anti_join is a dplyr function</span></span>
<span id="cb20-2"><a href="txt.html#cb20-2"></a>vacation_reddit_tt &lt;-<span class="st"> </span>vacation_tweets_tt <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">anti_join</span>(stop_words, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;word&quot;</span> =<span class="st"> &quot;word&quot;</span>)) </span></code></pre></div>
<blockquote>
<p>Technical Note: R is a functional(-like?) programming language (versus imperative programming, which is typically taught in school). A programming principle consistent with functional programming is immutability. Some would consider the code above poor practice as I am using the same variable on both sides of the equation versus creating a new variable, <code>vacation_tweets_tt</code>.</p>
</blockquote>
<p>Our analysis will be performed by date, that is, the field common to gold prices, stock prices, and social data is date. The date fields in the social data include time stamps - too granular of data for our purposes. We first convert the <code>created_at</code> from a date/timestamp to date field via the <strong>lubridate</strong><span class="citation">(Spinu, Grolemund, and Wickham <a href="#ref-R-lubridate" role="doc-biblioref">2020</a>)</span> package function <code>as_date()</code>. We then call the <strong>dplyr</strong> command <code>group_by()</code> to aggregate the rows by date, then <code>count()</code> the number of occurrences of each word by date.</p>
<p>Note the <code>%&gt;%</code> - this is a piping syntax where output of the previous command becomes input for the next command.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="txt.html#cb21-1"></a><span class="kw">library</span>(lubridate) <span class="co"># for the function as_date</span></span>
<span id="cb21-2"><a href="txt.html#cb21-2"></a></span>
<span id="cb21-3"><a href="txt.html#cb21-3"></a>vacation_tweets_tt<span class="op">$</span>created_at &lt;-<span class="st"> </span><span class="kw">as_date</span>(vacation_tweets_tt<span class="op">$</span>created_at) <span class="co"># By date, drop time stamp so we can generate a meaningful count by time</span></span>
<span id="cb21-4"><a href="txt.html#cb21-4"></a>tweet_word_count_by_date &lt;-<span class="st"> </span>vacation_tweets_tt <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(created_at) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(word, <span class="dt">sort =</span> <span class="ot">TRUE</span>) </span>
<span id="cb21-5"><a href="txt.html#cb21-5"></a><span class="kw">ungroup</span>(tweet_word_count_by_date)</span></code></pre></div>
<pre><code>## # A tibble: 1,243 x 3
##    created_at word          n
##    &lt;date&gt;     &lt;chr&gt;     &lt;int&gt;
##  1 2020-06-18 caribbean    25
##  2 2020-06-18 https        23
##  3 2020-06-18 t.co         23
##  4 2020-06-18 vacation     21
##  5 2020-06-11 caribbean    19
##  6 2020-06-11 vacation     18
##  7 2020-06-15 caribbean    18
##  8 2020-06-15 vacation     15
##  9 2020-06-11 https        14
## 10 2020-06-11 t.co         14
## # ... with 1,233 more rows</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="txt.html#cb23-1"></a>vacation_reddit_tt<span class="op">$</span>created_at &lt;-<span class="st"> </span><span class="kw">as_date</span>(vacation_reddit_tt<span class="op">$</span>created_at) </span>
<span id="cb23-2"><a href="txt.html#cb23-2"></a>reddit_word_count_by_date &lt;-<span class="st"> </span>vacation_reddit_tt <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(created_at) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(word, <span class="dt">sort =</span> <span class="ot">TRUE</span>) </span>
<span id="cb23-3"><a href="txt.html#cb23-3"></a><span class="kw">ungroup</span>(reddit_word_count_by_date)</span></code></pre></div>
<pre><code>## # A tibble: 1,243 x 3
##    created_at word          n
##    &lt;date&gt;     &lt;chr&gt;     &lt;int&gt;
##  1 2020-06-18 caribbean    25
##  2 2020-06-18 https        23
##  3 2020-06-18 t.co         23
##  4 2020-06-18 vacation     21
##  5 2020-06-11 caribbean    19
##  6 2020-06-11 vacation     18
##  7 2020-06-15 caribbean    18
##  8 2020-06-15 vacation     15
##  9 2020-06-11 https        14
## 10 2020-06-11 t.co         14
## # ... with 1,233 more rows</code></pre>
<p>Let’s combine the resulting Twitter and Reddit tokenized data. To keep track of the source, we will add a field called <code>source</code> with a value of <em>Twitter</em> or <em>Reddit</em> as appropriate (note that I use two different coding techniques to accomplish the same result). As the fields across the two sources are identical (because of the prior work narrowing the number of variables), we can simply append one data set to the other with a row bind command, <code>rbind()</code>.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="txt.html#cb25-1"></a>tweet_word_count_by_date &lt;-<span class="st"> </span><span class="kw">mutate</span>(tweet_word_count_by_date, <span class="dt">source =</span> <span class="st">&quot;Twitter&quot;</span>) <span class="co"># Adding field via mutate in dplyr</span></span>
<span id="cb25-2"><a href="txt.html#cb25-2"></a>reddit_word_count_by_date<span class="op">$</span>source &lt;-<span class="st"> &quot;Reddit&quot;</span> <span class="co"># Adding field using base R</span></span>
<span id="cb25-3"><a href="txt.html#cb25-3"></a></span>
<span id="cb25-4"><a href="txt.html#cb25-4"></a>social_data_count_by_date_word &lt;-<span class="st"> </span><span class="kw">rbind</span>(tweet_word_count_by_date, reddit_word_count_by_date)</span></code></pre></div>
<p>Sentiment analysis, that is, are the social media positive or negative expressions, is popular text analysis approach. Those in the text mining domain use lexicons - lists of words with ‘assigned emotion’ including: scores, negative/positive ratings, intensity, and even subtlety (e.g., negative as fear vs. negative as anger). Lexicons available to use include <em>bing</em>, <em>afinn</em>, <em>loughran</em>, and <em>nrc</em>. We will use <em>afinn</em> from the <strong>textdata</strong><span class="citation">(Hvitfeldt <a href="#ref-R-textdata" role="doc-biblioref">2020</a>)</span> package, which stores for each word in its data set a score from -5 (very negative) to 5 (very positive). To see the list, enter <code>get_sentiments("afinn")</code> in the Console prompt.</p>
<p>Our goal is to create one row for each date that reflects the opinions of the day based on the screened data. For each date, we will create an attribute for:</p>
<ul>
<li>number of words</li>
<li>total sentiment</li>
<li>count of negative words</li>
<li>number of times the word ‘Paris’ was used</li>
</ul>
<p>We use an inner join to combine the two sets. Keep in mind that using an inner join means that any word in the social data data set unrecognized in the <em>afinn</em> data set will be dropped. You may want to keep these words - they may even be the most meaningful. For instance, we searched Twitter by the word <em>Caribbean</em> but this word in not in <em>afinn</em>. A simple way to accomplish this goal is to create your own <em>afinn</em> data set, e.g., <code>afinn_custom &lt;- rbind(afinn, my_afinn)</code> where <code>my_afinn</code> is a custom data set of words with your sentiment rankings of the words, as shown in the code chunk below.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="txt.html#cb26-1"></a><span class="kw">library</span>(textdata) <span class="co"># Supports afinn, (-5 to 5), bing, loughran, and nrc lexicons</span></span>
<span id="cb26-2"><a href="txt.html#cb26-2"></a></span>
<span id="cb26-3"><a href="txt.html#cb26-3"></a>my_afinn &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">word =</span> <span class="kw">c</span>(<span class="st">&#39;Caribbean&#39;</span>, <span class="st">&#39;vacation&#39;</span>, <span class="st">&#39;beach&#39;</span>), <span class="dt">value =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)) </span>
<span id="cb26-4"><a href="txt.html#cb26-4"></a>afinn_custom &lt;-<span class="st"> </span><span class="kw">rbind</span>(my_afinn, <span class="kw">get_sentiments</span>(<span class="st">&quot;afinn&quot;</span>))</span>
<span id="cb26-5"><a href="txt.html#cb26-5"></a></span>
<span id="cb26-6"><a href="txt.html#cb26-6"></a>social_data_count_by_date_word &lt;-<span class="st"> </span><span class="kw">inner_join</span>(social_data_count_by_date_word, afinn_custom) <span class="co"># add the afinn variable of value</span></span>
<span id="cb26-7"><a href="txt.html#cb26-7"></a></span>
<span id="cb26-8"><a href="txt.html#cb26-8"></a>sentiment_data_by_date &lt;-<span class="st"> </span>social_data_count_by_date_word <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb26-9"><a href="txt.html#cb26-9"></a><span class="st">                          </span><span class="kw">group_by</span>(created_at) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb26-10"><a href="txt.html#cb26-10"></a><span class="st">                          </span><span class="kw">summarise</span>(<span class="dt">n =</span> <span class="kw">n</span>(),                                    <span class="co"># social media count</span></span>
<span id="cb26-11"><a href="txt.html#cb26-11"></a>                                    <span class="dt">total_sentiment =</span> <span class="kw">sum</span>(value),               <span class="co"># sum of sentiment</span></span>
<span id="cb26-12"><a href="txt.html#cb26-12"></a>                                    <span class="dt">negative_words =</span> <span class="kw">length</span>(value[value <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>]),  <span class="co"># occurrences of negative words</span></span>
<span id="cb26-13"><a href="txt.html#cb26-13"></a>                                    <span class="dt">Paris_count =</span> <span class="kw">length</span>(word[word <span class="op">==</span><span class="st"> &#39;Paris&#39;</span>]) <span class="co"># occurrences of the word &#39;Paris&#39;</span></span>
<span id="cb26-14"><a href="txt.html#cb26-14"></a>                                    )</span></code></pre></div>
<p>While Twitter only provides a week or so of data, you could collect and save the data over the course of the competition. You could save the data to your PC periodically via <code>saveRDS(sentiment_data_by_date, paste0("sentiment_data_by_date_", Sys.Date()))</code>. When you are ready to use the combined data set, open each RDS file via <code>openRDS(&lt;name of RDF file&gt;)</code>, combine them back to the <code>sentiment_data_by_date</code> tibble via <code>rbind()</code>, then remove duplicates via the command <code>sentiment_data_by_date &lt;- distinct(sentiment_data_by_date)</code> (from the <strong>dplyr</strong> package).</p>
<p>As you work through your text analysis, consider:</p>
<ul>
<li>Do you want to group by date? Or perhaps date and user?</li>
<li>Do you want to analyze words or sentences?</li>
<li>Do you need some additional preprocessing, e.g., remove certain words via <code>custom_stopwords &lt;- tibble(word = c("retweet", "covid", "etc"))</code></li>
</ul>
<hr>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-textdata">
<p>Hvitfeldt, Emil. 2020. <em>Textdata: Download and Load Various Text Datasets</em>. <a href="https://CRAN.R-project.org/package=textdata">https://CRAN.R-project.org/package=textdata</a>.</p>
</div>
<div id="ref-R-tidytext">
<p>Robinson, David, and Julia Silge. 2020. <em>Tidytext: Text Mining Using ’Dplyr’, ’Ggplot2’, and Other Tidy Tools</em>. <a href="https://CRAN.R-project.org/package=tidytext">https://CRAN.R-project.org/package=tidytext</a>.</p>
</div>
<div id="ref-R-lubridate">
<p>Spinu, Vitalie, Garrett Grolemund, and Hadley Wickham. 2020. <em>Lubridate: Make Dealing with Dates a Little Easier</em>. <a href="https://CRAN.R-project.org/package=lubridate">https://CRAN.R-project.org/package=lubridate</a>.</p>
</div>
<div id="ref-xie2020">
<p>Xie, Yihui. 2020a. <em>Bookdown: Authoring Books and Technical Documents with R Markdown</em>. 1st ed. Self Published: Chapman; Hall/CRC. <a href="https://bookdown.org/yihui/bookdown/">https://bookdown.org/yihui/bookdown/</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="comb.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
